\section{Datasets}
We used the following datasets:
\begin{itemize}
\item Congress (Kaggle)
\item Amazon (Kaggle)
\item KDD Cup 99 (\url{https://archive.ics.uci.edu/ml/datasets/KDD+Cup+1999+Data})
\item Lung Cancer (\url{https://archive.ics.uci.edu/ml/datasets/Lung+Cancer})
\end{itemize}

\section{Aproach \& Algorithms}
We performed our experiments using Python and Sklearn. Most of the experiments were performed on a Lenovo T420 while some of the more intense computations were performed on a server with a Intel(R) Xeon(R) CPU E5-2680 v2 and $\sim 160$ GB RAM. 

In our experiments compared the following algorithms from the library:
\begin{itemize}
\item Gaussian Naive Bayes (GNB)
\item Decision Tree \& Random Forest
\item SVM (\verb|svm.SVC|)
\item \verb|KNeighborsClassifier| (kNN)
\end{itemize}

Unless stated otherwise, we tested the algorithms using $10-$fold cross validation. 

All data was scaled using the corresponding function from numpy. 
